import json
import requests
import time
import streamlit as st
import pandas as pd
from .db_utils import Database

# ‡∏™‡∏£‡πâ‡∏≤‡∏á global database instance
db = Database()

def load_datasets():
    """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    try:
        data = db.get_datasets()
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
        df = pd.DataFrame(data)
        column_mapping = {
            'title': 'title',
            'organization': 'organization',
            'resource_count': 'resource_count',
            'file_types': 'file_types',
            'last_updated': 'last_updated',
            'package_id': 'package_id',
            'url': 'url'
        }
        # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
        df = df.rename(columns=column_mapping)
        return df
    except Exception as e:
        st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ: {str(e)}")
        return None

def update_dataset(dataset_id):
    """‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö dataset ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏"""
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á progress bar
    progress_text = "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•..."
    progress_bar = st.progress(0, text=progress_text)
    
    try:
        print(f"\nüîÑ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö dataset ID: {dataset_id}")
        
        # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å API
        progress_bar.progress(0.2, text="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å API...")
        PACKAGE_SHOW_URL = f"https://data.go.th/api/3/action/package_show?id={dataset_id}"
        response = requests.get(PACKAGE_SHOW_URL, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        if not data.get("success"):
            progress_bar.empty()
            print("‚ùå API ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ")
            return "‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å API ‡πÑ‡∏î‡πâ"
        
        # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°
        progress_bar.progress(0.4, text="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°...")
        try:
            with open('data/processed/datasets.json', 'r', encoding='utf-8') as f:
                datasets = json.load(f)
            print("‚úÖ ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        except Exception as e:
            progress_bar.empty()
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå datasets.json: {str(e)}")
            return f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°: {str(e)}"
        
        # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        progress_bar.progress(0.6, text="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
        package = data['result']
        
        # ‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        for i, dataset in enumerate(datasets):
            if dataset['package_id'] == dataset_id:
                # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
                datasets[i].update({
                    'title': package.get('title', ''),
                    'organization': package.get('organization', {}).get('title', ''),
                    'url': package.get('url', ''),
                    'last_updated': package.get('metadata_modified', '')
                })
                
                # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£
                resources = package.get('resources', [])
                datasets[i]['resource_count'] = len(resources)
                
                # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå
                file_types = set()
                for resource in resources:
                    if resource.get('format'):
                        file_types.add(resource['format'].upper())
                datasets[i]['file_types'] = ', '.join(sorted(file_types))
                
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ü‡∏•‡πå
                try:
                    with open('data/processed/resources.json', 'r', encoding='utf-8') as f:
                        all_files = json.load(f)
                except:
                    all_files = []
                
                # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ü‡∏•‡πå
                dataset_files = []
                for resource in resources:
                    file_info = {
                        'dataset_id': dataset_id,
                        'file_name': resource.get('name', ''),
                        'format': resource.get('format', '').upper(),
                        'url': resource.get('url', ''),
                        'description': resource.get('description', '')
                    }
                    dataset_files.append(file_info)
                
                # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤‡∏Ç‡∏≠‡∏á dataset ‡∏ô‡∏µ‡πâ
                all_files = [f for f in all_files if f['dataset_id'] != dataset_id]
                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà
                all_files.extend(dataset_files)
                
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ü‡∏•‡πå
                with open('data/processed/resources.json', 'w', encoding='utf-8') as f:
                    json.dump(all_files, f, ensure_ascii=False, indent=2)
                
                break
        
        # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        progress_bar.progress(0.8, text="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
        with open('data/processed/datasets.json', 'w', encoding='utf-8') as f:
            json.dump(datasets, f, ensure_ascii=False, indent=2)
        
        # ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô
        progress_bar.progress(1.0, text="‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        time.sleep(1)
        progress_bar.empty()
        
        print(f"‚úÖ ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {dataset_id}\n")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó session state
        if 'last_update' not in st.session_state:
            st.session_state.last_update = {}
        st.session_state.last_update[dataset_id] = time.time()
        
        return "‚úÖ ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à"
        
    except Exception as e:
        progress_bar.empty()
        error_msg = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"
        print(f"‚ùå {error_msg}")
        return f"‚ùå {error_msg}"

def update_dataset_ranking(dataset_id, ranking):
    """‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó ranking ‡∏Ç‡∏≠‡∏á dataset"""
    return db.update_dataset_ranking(dataset_id, ranking)

def get_dataset_files(dataset_id):
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏≠‡∏á dataset"""
    return db.get_dataset_files(dataset_id) 