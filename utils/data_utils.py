import json
import requests
import time
import streamlit as st
import pandas as pd
from .db_utils import Database
import os

# ‡∏™‡∏£‡πâ‡∏≤‡∏á global database instance
db = Database()

def init_database():
    """‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ"""
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏Ñ‡∏¢‡∏£‡∏±‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if 'db_initialized' in st.session_state:
        return True

    print("\nüîÑ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")

    has_sqlite = os.path.exists('data/database.sqlite')
    json_files = {
        'datasets': 'data/datasets_info.json',
        'resources': 'data/dataset_files.json'
    }
    has_json = all(os.path.exists(path) for path in json_files.values())

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô SQLite ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if has_sqlite:
        try:
            cursor = db.conn.execute("SELECT COUNT(*) FROM datasets")
            count = cursor.fetchone()[0]
            if count > 0:
                print(f"‚úÖ ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• SQLite ‡πÅ‡∏•‡πâ‡∏ß ({count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)")
                st.session_state.db_initialized = True
                return True
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {str(e)}")
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ‡πÉ‡∏´‡πâ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå database ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
            try:
                os.remove('data/database.sqlite')
                print("üîÑ ‡∏•‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà")
                has_sqlite = False
            except:
                pass

    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå JSON ‡πÉ‡∏´‡πâ migrate ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô
    if has_json:
        print("\nüì• ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå JSON ‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£ migrate...")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô JSON
        try:
            with open(json_files['datasets'], 'r', encoding='utf-8') as f:
                datasets = json.load(f)
            with open(json_files['resources'], 'r', encoding='utf-8') as f:
                resources = json.load(f)
            print(f"üìä ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(datasets)} ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÅ‡∏•‡∏∞ {len(resources)} ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£")
        except Exception as e:
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON: {str(e)}")
            datasets = []
            resources = []

        # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô JSON ‡πÉ‡∏´‡πâ migrate
        if len(datasets) > 0 and len(resources) > 0:
            print("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á migrate ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
            if db.migrate_from_json():
                print("‚úÖ Migrate ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                st.session_state.db_initialized = True
                return True
            else:
                print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ migrate ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ")
        else:
            print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON")

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á SQLite ‡πÅ‡∏•‡∏∞ JSON
    if not has_sqlite and not has_json:
        print("\nüîÑ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á...")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        sample_data = {
            'datasets': [{
                'package_id': 'sample',
                'title': '‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•',
                'organization': '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á',
                'url': 'https://data.go.th',
                'resource_count': 1,
                'file_types': 'CSV',
                'last_updated': '2024-03-19'
            }],
            'resources': [{
                'dataset_id': 'sample',
                'file_name': 'sample.csv',
                'format': 'CSV',
                'url': 'https://data.go.th',
                'description': '‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á',
                'ranking': 4
            }]
        }
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á database
        if db.init_sample_data(sample_data):
            print("‚úÖ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
            st.session_state.db_initialized = True
            return True
        else:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏î‡πâ")
            return False

    return False

def load_datasets():
    """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
    if not init_database():
        st.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ")
        return None
    
    try:
        data = db.get_datasets()
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
        df = pd.DataFrame(data)
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
        print("Columns in DataFrame:", df.columns.tolist())
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
        print("\nSample data:")
        print(df.head())
        
        # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏ô SQL ‡πÅ‡∏•‡πâ‡∏ß
        return df
    except Exception as e:
        print(f"Error loading datasets: {str(e)}")
        st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ: {str(e)}")
        return None

def update_dataset(package_id):
    """‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• dataset"""
    try:
        # ... existing code ...
    except Exception as e:
        return f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"

def update_dataset_ranking(dataset_id, ranking):
    """‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó ranking ‡∏Ç‡∏≠‡∏á dataset"""
    return db.update_dataset_ranking(dataset_id, ranking)

def get_dataset_files(package_id):
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏≠‡∏á dataset ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏"""
    db = Database()
    return db.get_dataset_files(package_id)

def get_dataset_rankings(package_ids):
    """‡∏î‡∏∂‡∏á ranking ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏¢ datasets ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô"""
    db = Database()
    return db.get_dataset_rankings(package_ids) 